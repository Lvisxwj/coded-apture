import torch

# 归一化，每个数据集都有一个standerd，dataset/standerd

def max_min_norm(input_data):
    """
    对4维数据的每个通道进行Min-Max归一化，使用预设的每个通道的最小值和最大值。
    参数：
    - input_data: 输入数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = input_data.shape

    # 预设的最小值和最大值列表（32个通道的值）
    max_values = torch.tensor([
        3654, 640320, 0.68508, 14, 6.33333, 22.3506, 0.0010135, 0.0017025,
        2104.53, 1.13444, 15.4096, 2.44174, 0.756353, 13206, 0.779797, 1630, 2.79939,
        0.881562, 2.42226, 24288.5, 1.15107, 0.914317, 0.93173, 90.0882, 17182.6,
        7446.72, 7.2086, 0.445404, -0.162209, 0.00155797, 1.12579, 1.08031
    ])

    min_values = torch.tensor([
        -5770, -757080, -0.411147, -3.4, -2.2, 0.80512, -0.000382122, -0.000387671,
        -2852.4, -0.641313, -0.416895, -0.351643, -0.427581, -8364, -0.559531, -2980, 0.092725,
        -1.04776, -0.419541, -27577.2, -2.28623, -0.398923, -0.0343407, -41.8549, -15440.6,
        -8535.6, 0.400971, -0.795348, -0.922897, -0.000430041, 0.0448032, 0.0327779
    ])

    # 确保通道数为32
    assert channel == 32, "输入数据的通道数必须为32"

    # 初始化输出 (使用 torch.zeros_like)
    output_data = torch.zeros_like(input_data)

    # 对每个通道进行Min-Max归一化
    for i in range(channel):
        output_data[:, i, :, :] = (input_data[:, i, :, :] - min_values[i]) / (max_values[i] - min_values[i])

    return output_data

def reverse_max_min_norm(normalized_data):
    """
    对经过Min-Max归一化的数据进行反归一化，恢复到原始数据。
    参数：
    - normalized_data: 已经归一化的数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 反归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = normalized_data.shape

    # 预设的最小值和最大值列表（32个通道的值），与归一化时保持一致
    max_values = torch.tensor([
        3654, 640320, 0.68508, 14, 6.33333, 22.3506, 0.0010135, 0.0017025,
        2104.53, 1.13444, 15.4096, 2.44174, 0.756353, 13206, 0.779797, 1630, 2.79939,
        0.881562, 2.42226, 24288.5, 1.15107, 0.914317, 0.93173, 90.0882, 17182.6,
        7446.72, 7.2086, 0.445404, -0.162209, 0.00155797, 1.12579, 1.08031
    ])

    min_values = torch.tensor([
        -5770, -757080, -0.411147, -3.4, -2.2, 0.80512, -0.000382122, -0.000387671,
        -2852.4, -0.641313, -0.416895, -0.351643, -0.427581, -8364, -0.559531, -2980, 0.092725,
        -1.04776, -0.419541, -27577.2, -2.28623, -0.398923, -0.0343407, -41.8549, -15440.6,
        -8535.6, 0.400971, -0.795348, -0.922897, -0.000430041, 0.0448032, 0.0327779
    ])

    # 确保通道数为32
    assert channel == 32, "输入数据的通道数必须为32"

    # 初始化输出 (使用 torch.zeros_like)
    original_data = torch.zeros_like(normalized_data)

    # 对每个通道进行反归一化
    for i in range(channel):
        original_data[:, i, :, :] = normalized_data[:, i, :, :] * (max_values[i] - min_values[i]) + min_values[i]

    return original_data

def XA_max_min_norm(input_data):
    """
    对4维数据的每个通道进行Min-Max归一化，使用预设的每个通道的最小值和最大值。
    参数：
    - input_data: 输入数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = input_data.shape

    max_values = torch.tensor([
        3025, 521360, 0.284532, 837, 391, 3.48898, 0.000136779, 0.00020001,
        1747.45, 0.720419, 1.79104, 0.905292, 0.480308, 5143, 0.553202, 8735, 1.93984,
        0.733002, 1.26033, 13228.1, 0.905988, 0.671108, 0.591036, 64.2795, 10269.4,
        8670.99, 2.84843, 0.282241, 0, 0.000164337, 1.18954, 1.56656
    ])

    min_values = torch.tensor([
        -2702, -469620, -0.284098, -1097, -663, 0, -4.57047e-05, -0.000132116,
        -4198.1, -0.579791, -0.50372, -0.245862, -0.386539, -7479, -0.44216, -8405, 0,
        -0.681453, -0.321003, -15411.6, -1.26246, -0.294866, -0.199074, -32.8796, -9767.28,
        -9418.38, 0, -0.365827, -0.915261, -0.000176148, 0, 0
    ])

    # 确保通道数为32
    assert channel == 32, "输入数据的通道数必须为32"

    # 初始化输出 (使用 torch.zeros_like)
    output_data = torch.zeros_like(input_data)

    # 对每个通道进行Min-Max归一化
    for i in range(channel):
        output_data[:, i, :, :] = (input_data[:, i, :, :] - min_values[i]) / (max_values[i] - min_values[i])

    return output_data

def reverse_XA_max_min_norm(normalized_data):
    """
    对经过Min-Max归一化的数据进行反归一化，恢复到原始数据。
    参数：
    - normalized_data: 已经归一化的数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 反归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = normalized_data.shape

    # 预设的最小值和最大值列表（32个通道的值），与归一化时保持一致
    max_values = torch.tensor([
        3025, 521360, 0.284532, 837, 391, 3.48898, 0.000136779, 0.00020001,
        1747.45, 0.720419, 1.79104, 0.905292, 0.480308, 5143, 0.553202, 8735, 1.93984,
        0.733002, 1.26033, 13228.1, 0.905988, 0.671108, 0.591036, 64.2795, 10269.4,
        8670.99, 2.84843, 0.282241, 0, 0.000164337, 1.18954, 1.56656
    ])

    min_values = torch.tensor([
        -2702, -469620, -0.284098, -1097, -663, 0, -4.57047e-05, -0.000132116,
        -4198.1, -0.579791, -0.50372, -0.245862, -0.386539, -7479, -0.44216, -8405, 0,
        -0.681453, -0.321003, -15411.6, -1.26246, -0.294866, -0.199074, -32.8796, -9767.28,
        -9418.38, 0, -0.365827, -0.915261, -0.000176148, 0, 0
    ])

    # 确保通道数为32
    assert channel == 32, "输入数据的通道数必须为32"

    # 初始化输出 (使用 torch.zeros_like)
    original_data = torch.zeros_like(normalized_data)

    # 对每个通道进行反归一化
    for i in range(channel):
        original_data[:, i, :, :] = normalized_data[:, i, :, :] * (max_values[i] - min_values[i]) + min_values[i]

    return original_data

def Chi_max_min_norm(input_data):
    """
    对4维数据的每个通道进行Min-Max归一化，使用预设的每个通道的最小值和最大值。
    参数：
    - input_data: 输入数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = input_data.shape

    max_values = torch.tensor([
        1598, 388400, 0.800098, 1037, 747, 3632, 0.320175, 0.327451,
        1049.74, 1.49886, 18.8421, 2.19722, 1, 8300, 0.99996, 6380, 402,
        1, 61.4654, 9909.96, 5.15174, 1.15995, 1, 74.9172, 8366.68,
        3588, 1780, 1, 1, 0.0337637, 4.11732, 7.81148
    ])

    min_values = torch.tensor([
        -2504, -205340, -0.777778, -943, -269, 0, -0.00252438, -0.00521619,
        -1015.39, -1.46301, -0.983088, -0.950081, -0.978022, -2145, -1.29884, -7920, 0,
        -12.4753, -0.902503, -7865.28, -4.73155, -1.01309, -0.966835, -34.035, -3424.88,
        -83119.8, 0, -0.817035, -0.99778, -0.00433179, 0, 0
    ])

    # 确保通道数为32
    assert channel == 32, "输入数据的通道数必须为32"

    # 初始化输出 (使用 torch.zeros_like)
    output_data = torch.zeros_like(input_data)

    # 对每个通道进行Min-Max归一化
    for i in range(channel):
        output_data[:, i, :, :] = (input_data[:, i, :, :] - min_values[i]) / (max_values[i] - min_values[i])

    return output_data

def reverse_Chi_max_min_norm(normalized_data):
    """
    对经过Min-Max归一化的数据进行反归一化，恢复到原始数据。
    参数：
    - normalized_data: 已经归一化的数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 反归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = normalized_data.shape

    # 预设的最小值和最大值列表（32个通道的值），与归一化时保持一致
    max_values = torch.tensor([
        1598, 388400, 0.800098, 1037, 747, 3632, 0.320175, 0.327451,
        1049.74, 1.49886, 18.8421, 2.19722, 1, 8300, 0.99996, 6380, 402,
        1, 61.4654, 9909.96, 5.15174, 1.15995, 1, 74.9172, 8366.68,
        3588, 1780, 1, 1, 0.0337637, 4.11732, 7.81148
    ])

    min_values = torch.tensor([
        -2504, -205340, -0.777778, -943, -269, 0, -0.00252438, -0.00521619,
        -1015.39, -1.46301, -0.983088, -0.950081, -0.978022, -2145, -1.29884, -7920, 0,
        -12.4753, -0.902503, -7865.28, -4.73155, -1.01309, -0.966835, -34.035, -3424.88,
        -83119.8, 0, -0.817035, -0.99778, -0.00433179, 0, 0
    ])

    # 确保通道数为32
    assert channel == 32, "输入数据的通道数必须为32"

    # 初始化输出 (使用 torch.zeros_like)
    original_data = torch.zeros_like(normalized_data)

    # 对每个通道进行反归一化
    for i in range(channel):
        original_data[:, i, :, :] = normalized_data[:, i, :, :] * (max_values[i] - min_values[i]) + min_values[i]

    return original_data

def HSI_max_min_norm(input_data):
    """
    对4维数据的每个通道进行Min-Max归一化，使用预设的每个通道的最小值和最大值。
    参数：
    - input_data: 输入数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = input_data.shape

    max_values = torch.tensor([
        1339.0, 1501.0, 1621.0, 1683.0, 1701.0, 1937.0, 2165.0, 2263.0,
        2413.0, 2497.0, 2697.0, 2987.0, 3075.0, 3103.0, 3085.0, 3021.0, 3257.0,
        3489.0, 3699.0, 3705.0, 3787.0, 3909.0, 4223.0, 4743.0, 5173.0,
        5601.0, 5813.0, 5893.0, 5933.0, 6545.0, 7153.0, 7703.0, 8019.0,
        8601.0, 8841.0, 8887.0, 9047.0, 9177.0, 9421.0, 9959.0, 10737.0,
        11079.0, 11383.0, 11733.0, 11649.0, 11877.0, 11997.0, 12163.0, 12487.0,
        12775.0, 13319.0, 13535.0, 13719.0, 13397.0, 12837.0, 12003.0, 11629.0,
        11179.0, 10939.0, 10965.0, 11355.0, 11795.0, 12041.0, 12351.0, 12407.0,
        12349.0, 12091.0, 11753.0, 10997.0, 10685.0, 10425.0, 10293.0, 10467.0,
        10439.0, 10831.0, 10967.0, 10907.0, 10931.0, 10675.0, 10419.0, 10197.0,
        9515.0, 9257.0, 8777.0
    ])

    min_values = torch.tensor([
        455.0, 459.0, 455.0, 457.0, 457.0, 459.0, 459.0, 453.0,
        463.0, 461.0, 463.0, 467.0, 461.0, 461.0, 465.0, 461.0, 465.0,
        463.0, 469.0, 465.0, 467.0, 467.0, 469.0, 469.0, 471.0,
        473.0, 467.0, 467.0, 473.0, 473.0, 475.0, 473.0, 473.0,
        477.0, 479.0, 475.0, 479.0, 479.0, 477.0, 477.0, 479.0,
        485.0, 477.0, 485.0, 477.0, 485.0, 485.0, 483.0, 487.0,
        489.0, 495.0, 495.0, 497.0, 495.0, 505.0, 511.0, 511.0,
        513.0, 515.0, 517.0, 517.0, 511.0, 519.0, 525.0, 519.0,
        523.0, 527.0, 521.0, 517.0, 519.0, 515.0, 513.0, 517.0,
        513.0, 517.0, 513.0, 517.0, 511.0, 509.0, 507.0, 509.0,
        513.0, 511.0, 507.0
    ])

    assert channel == 84, "输入数据的通道数必须为84"

    # 初始化输出 (使用 torch.zeros_like)
    output_data = torch.zeros_like(input_data)

    # 对每个通道进行Min-Max归一化
    for i in range(channel):
        output_data[:, i, :, :] = (input_data[:, i, :, :] - min_values[i]) / (max_values[i] - min_values[i])

    return output_data

def HSI_reverse_max_min_norm(normalized_data):
    """
    对经过Min-Max归一化的数据进行反归一化，恢复到原始数据。
    参数：
    - normalized_data: 已经归一化的数据，形状为 [bs, channel, W, H]，类型为 PyTorch Tensor

    返回：
    - 反归一化后的数据，形状与输入相同，类型为 PyTorch Tensor
    """
    bs, channel, W, H = normalized_data.shape

    max_values = torch.tensor([
        1339.0, 1501.0, 1621.0, 1683.0, 1701.0, 1937.0, 2165.0, 2263.0,
        2413.0, 2497.0, 2697.0, 2987.0, 3075.0, 3103.0, 3085.0, 3021.0, 3257.0,
        3489.0, 3699.0, 3705.0, 3787.0, 3909.0, 4223.0, 4743.0, 5173.0,
        5601.0, 5813.0, 5893.0, 5933.0, 6545.0, 7153.0, 7703.0, 8019.0,
        8601.0, 8841.0, 8887.0, 9047.0, 9177.0, 9421.0, 9959.0, 10737.0,
        11079.0, 11383.0, 11733.0, 11649.0, 11877.0, 11997.0, 12163.0, 12487.0,
        12775.0, 13319.0, 13535.0, 13719.0, 13397.0, 12837.0, 12003.0, 11629.0,
        11179.0, 10939.0, 10965.0, 11355.0, 11795.0, 12041.0, 12351.0, 12407.0,
        12349.0, 12091.0, 11753.0, 10997.0, 10685.0, 10425.0, 10293.0, 10467.0,
        10439.0, 10831.0, 10967.0, 10907.0, 10931.0, 10675.0, 10419.0, 10197.0,
        9515.0, 9257.0, 8777.0
    ])

    min_values = torch.tensor([
        455.0, 459.0, 455.0, 457.0, 457.0, 459.0, 459.0, 453.0,
        463.0, 461.0, 463.0, 467.0, 461.0, 461.0, 465.0, 461.0, 465.0,
        463.0, 469.0, 465.0, 467.0, 467.0, 469.0, 469.0, 471.0,
        473.0, 467.0, 467.0, 473.0, 473.0, 475.0, 473.0, 473.0,
        477.0, 479.0, 475.0, 479.0, 479.0, 477.0, 477.0, 479.0,
        485.0, 477.0, 485.0, 477.0, 485.0, 485.0, 483.0, 487.0,
        489.0, 495.0, 495.0, 497.0, 495.0, 505.0, 511.0, 511.0,
        513.0, 515.0, 517.0, 517.0, 511.0, 519.0, 525.0, 519.0,
        523.0, 527.0, 521.0, 517.0, 519.0, 515.0, 513.0, 517.0,
        513.0, 517.0, 513.0, 517.0, 511.0, 509.0, 507.0, 509.0,
        513.0, 511.0, 507.0
    ])

    assert channel == 84, "输入数据的通道数必须为84"

    # 初始化输出 (使用 torch.zeros_like)
    original_data = torch.zeros_like(normalized_data)

    # 对每个通道进行反归一化
    for i in range(channel):
        original_data[:, i, :, :] = normalized_data[:, i, :, :] * (max_values[i] - min_values[i]) + min_values[i]

    return original_data